{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 決定木分類器：意味解釈可能性に配慮する場合に魅力的\n",
    "* 意味解釈可能性(interpretability):得られた結果の意味を解釈しやすいかどうか\n",
    "* 情報利得(Information gain):分割された集合の要素についてのばらつきの減少\n",
    "* 葉が純粋になる：分割されたデータのばらつきの減少がなくなる（=IGが最大）\n",
    "\n",
    "## 決定木の目的関数\n",
    "\n",
    "情報利得を最大化するようにする。\n",
    "\n",
    "$$ IG(D_p,f) = I(D_p)- \\sum_{i=1}^m \\frac{N_j}{N_p}I(D_j) $$\n",
    "\n",
    "* \\\\( f \\\\):分割を行う特徴量\n",
    "* \\\\( D_p \\\\):親ノードのデータセット\n",
    "* \\\\( D_j \\\\):j番目の子ノードのデータセット\n",
    "* \\\\( I \\\\):不純度(ノードに異なるクラスのサンプルがどの程度の割合で混ざっているかを表す指標)\n",
    "* \\\\( N_p \\\\):親ノードのサンプルの総数\n",
    "* \\\\( N_j \\\\):j番目の子ノードのサンプルの個数\n",
    "* 子ノードの不純度が低いほど情報利得は大きくなる\n",
    "\n",
    "## 二分決定木\n",
    "\n",
    "組み合わせ探索空間を減らすために2つの子ノードにする\n",
    "\n",
    "$$ IG(D_p,f) = I(D_p)- \\frac{N_{left}}{N_p}I(D_{left}) - \\frac{N_{right}}{N_p}I(D_{right}) $$\n",
    "\n",
    "#### 二分決定木でよく使用される不純度の指標または分割条件\n",
    "\n",
    "* ジニ不純度(Gini impurity):\\\\( I_G \\\\)\n",
    "* エントロピー(entropy):\\\\( I_H \\\\)\n",
    "* 分類誤差(classification error):\\\\( I_E \\\\)\n",
    "\n",
    "### エントロピー\n",
    "\n",
    "エントロピーは相互情報量(2つの確率の相互依存度)が最大化するように試みる条件である\n",
    "\n",
    "$$ I_H(t) = -\\sum_{i=1}^c p(i|t)\\log_2 p(i|t) $$\n",
    "\n",
    "* \\\\( p(i|t) \\\\):特定のノードtに暮らすiに属するサンプルの割合\n",
    "* 全てのサンプルが同じクラスに属しているとエントロピーは0\n",
    "* 二値分類で双方のクラスに一様に分布するとエントロピーは1(こちらにしたい)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
